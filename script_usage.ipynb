{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Traceback (most recent call last):\n  File \"detect_image.py\", line 144, in <module>\n    main()\n  File \"detect_image.py\", line 84, in main\n    dataset = ImageFolder(args.input_path, img_size)\n  File \"/data/notebook/pystyle/pytorch/pytorch-yolov3/pytorch-yolov3/yolov3/datasets/imagefolder.py\", line 17, in __init__\n    raise FileExistsError(f\"image path {img_path_or_dir} does not exist.\")\nFileExistsError: image path data/dog.jpg does not exist.\n"
     ]
    }
   ],
   "source": [
    "!python detect_image.py \\\n",
    "    --input_path data/dog.png \\\n",
    "    --weights_path weights/yolov3.weights \\\n",
    "    --gpu_id 0 \\\n",
    "    --config_path config/yolov3_coco.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Darknet format weights file loaded. weights/yolov3.weights\n",
      "infer:   0%|                                              | 0/1 [00:00<?, ?it/s][{'confidence': 0.9938858151435852, 'class_id': 1, 'class_name': 'bicycle', 'x1': 164, 'y1': 113, 'x2': 562, 'y2': 445}, {'confidence': 0.9299834966659546, 'class_id': 7, 'class_name': 'truck', 'x1': 473, 'y1': 85, 'x2': 689, 'y2': 170}, {'confidence': 0.9872578382492065, 'class_id': 16, 'class_name': 'dog', 'x1': 128, 'y1': 224, 'x2': 313, 'y2': 536}]\n",
      "infer: 100%|██████████████████████████████████████| 1/1 [00:00<00:00, 22.62it/s]\n",
      "Average inference time: 0.045 s/image\n",
      "data/dog.png\n",
      "   confidence  class_id class_name   x1   y1   x2   y2\n",
      "0    0.993886         1    bicycle  164  113  562  445\n",
      "1    0.929983         7      truck  473   85  689  170\n",
      "2    0.987258        16        dog  128  224  313  536\n"
     ]
    }
   ],
   "source": [
    "!python detect_image.py \\\n",
    "    --input_path data/dog.png \\\n",
    "    --weights_path weights/yolov3.weights \\\n",
    "    --gpu_id 0 \\\n",
    "    --config_path config/yolov3_coco.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infer video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR:0] global /tmp/pip-install-vjo4ps1a/opencv-python/opencv/modules/videoio/src/cap.cpp (142) open VIDEOIO(CV_IMAGES): raised OpenCV exception:\n",
      "\n",
      "OpenCV(4.5.1) /tmp/pip-install-vjo4ps1a/opencv-python/opencv/modules/videoio/src/cap_images.cpp:253: error: (-5:Bad argument) CAP_IMAGES: can't find starting number (in the name of file): data/sample.avi in function 'icvExtractPattern'\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"detect_video.py\", line 143, in <module>\n",
      "    main()\n",
      "  File \"detect_video.py\", line 104, in main\n",
      "    dataset = Video(args.input_path, img_size)\n",
      "  File \"/data/notebook/pystyle/pytorch/pytorch-yolov3/pytorch-yolov3/yolov3/datasets/video.py\", line 12, in __init__\n",
      "    assert self.cap.isOpened(), f\"Failed to open video file {video_path}.\"\n",
      "AssertionError: Failed to open video file data/sample.avi.\n"
     ]
    }
   ],
   "source": [
    "!python detect_video.py \\\n",
    "    --input_path data/sample.avi \\\n",
    "    --weights_path weights/yolov3.weights \\\n",
    "    --gpu_id 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infer image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Darknet format weights file loaded. weights/yolov3.weights\n",
      "infer:   0%|                                              | 0/1 [00:00<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"detect_image.py\", line 140, in <module>\n",
      "    main()\n",
      "  File \"detect_image.py\", line 106, in main\n",
      "    for inputs, pad_infos, paths in tqdm(dataloader, desc=\"infer\"):\n",
      "  File \"/root/.pyenv/versions/3.8.3/lib/python3.8/site-packages/tqdm/std.py\", line 1129, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"/root/.pyenv/versions/3.8.3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 345, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/root/.pyenv/versions/3.8.3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 385, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "  File \"/root/.pyenv/versions/3.8.3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/root/.pyenv/versions/3.8.3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/data/notebook/pystyle/pytorch/pytorch-yolov3/pytorch-yolov3/yolov3/datasets/imagefolder.py\", line 24, in __getitem__\n",
      "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
      "cv2.error: OpenCV(4.5.1) /tmp/pip-install-vjo4ps1a/opencv-python/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python detect_image.py \\\n",
    "    --input_path s.jpg \\\n",
    "    --weights_path weights/yolov3.weights \\\n",
    "    --gpu_id 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infer images in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Darknet format weights file loaded. weights/yolov3.weights\n",
      "infer: 100%|██████████████████████████████████████| 1/1 [00:00<00:00,  3.93it/s]\n",
      "Average inference time: 0.028 s/image\n",
      "data/dog.png\n",
      "   confidence  class_id class_name   x1   y1   x2   y2\n",
      "0    0.993886         1    bicycle  164  113  562  445\n",
      "1    0.929983         7      truck  473   85  689  170\n",
      "2    0.987258        16        dog  128  224  313  536\n",
      "data/eagle.png\n",
      "   confidence  class_id class_name   x1  y1   x2   y2\n",
      "0    0.996777        14       bird  130  81  608  446\n",
      "data/field.png\n",
      "   confidence  class_id class_name   x1   y1   x2   y2\n",
      "0    0.999895         0     person  190   93  276  371\n",
      "1    0.992693        16        dog   63  266  206  348\n",
      "2    0.996616        17      horse  394  136  602  350\n",
      "data/giraffe.png\n",
      "   confidence  class_id class_name   x1   y1   x2   y2\n",
      "0    0.957604        22      zebra  263  200  434  451\n",
      "1    0.997591        23    giraffe  152   48  440  434\n",
      "2    0.627597        23    giraffe  248  184  432  415\n",
      "data/herd_of_horses.png\n",
      "   confidence  class_id class_name   x1   y1   x2   y2\n",
      "0    0.979450        17      horse    6  190  329  424\n",
      "1    0.967602        17      horse  229  183  451  361\n",
      "2    0.920163        17      horse  437  206  598  347\n",
      "3    0.887599        17      horse    4  176  157  372\n",
      "data/messi.png\n",
      "   confidence  class_id class_name    x1   y1    x2   y2\n",
      "0    0.998218         0     person    48   17   794  731\n",
      "1    0.996880         0     person  1207  474  1292  695\n",
      "2    0.992051         0     person   616  113  1134  728\n",
      "data/person.png\n",
      "   confidence  class_id class_name  x1   y1   x2   y2\n",
      "0    0.997092         0     person   3   23  363  487\n",
      "1    0.937791        16        dog  48  234  183  362\n",
      "data/room.png\n",
      "   confidence  class_id class_name   x1   y1   x2   y2\n",
      "0    0.951407        56      chair  163  264  269  367\n",
      "1    0.910221        56      chair    2  243   68  372\n",
      "2    0.747469        56      chair  256  216  310  327\n",
      "3    0.695840        74      clock  455  151  473  167\n",
      "data/street.png\n",
      "   confidence  class_id     class_name   x1   y1   x2   y2\n",
      "0    0.999235         2            car  230  330  331  376\n",
      "1    0.994365         2            car   83  326  115  348\n",
      "2    0.992382         2            car  108  326  148  352\n",
      "3    0.982408         2            car  361  331  496  387\n",
      "4    0.976825         2            car  140  323  190  358\n",
      "5    0.971177         2            car  172  328  254  363\n",
      "6    0.807686         2            car    2  324   12  342\n",
      "7    0.685551         7          truck   13  312   84  366\n",
      "8    0.934733         9  traffic light  382  108  409  165\n"
     ]
    }
   ],
   "source": [
    "!python detect_image.py \\\n",
    "    --input_path data \\\n",
    "    --weights_path weights/yolov3.weights \\\n",
    "    --gpu_id 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate COCO dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Darknet format weights file loaded. weights/yolov3.weights\n",
      "loading annotations into memory...\n",
      "Done (t=0.53s)\n",
      "creating index...\n",
      "index created!\n",
      "infer: 100%|██████████████████████████████████████| 1/1 [00:00<00:00,  8.92it/s]\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.07s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.08s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.274\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.503\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.232\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.124\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.586\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.420\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.186\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.338\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.369\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.207\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.600\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.500\n",
      "0.27363823991403036 0.5025840256836743\n"
     ]
    }
   ],
   "source": [
    "!python evaluate_coco.py \\\n",
    "    --dataset_dir /data/COCO \\\n",
    "    --anno_path config/instances_val5k.json \\\n",
    "    --weights_path weights/yolov3.weights \\\n",
    "    --gpu_id 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.59s)\n",
      "creating index...\n",
      "index created!\n",
      "loss ====> 57.57133483886719\n",
      "0.17648935317993164\n"
     ]
    }
   ],
   "source": [
    "!python train_coco.py \\\n",
    "    --dataset_dir /data/COCO \\\n",
    "    --anno_path /data/COCO/annotations/instances_val5k.json \\\n",
    "    --weights_path weights/yolov3.weights \\\n",
    "    --gpu_id 0  # 0.3256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train COCO dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=15.51s)\n",
      "creating index...\n",
      "index created!\n",
      "Traceback (most recent call last):\n",
      "  File \"train_coco.py\", line 203, in <module>\n",
      "    main()\n",
      "  File \"train_coco.py\", line 156, in main\n",
      "    loss = model(imgs, targets)\n",
      "  File \"/root/.pyenv/versions/3.8.3/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/data/notebook/pystyle/pytorch/pytorch-yolov3/pytorch-yolov3/yolov3/models/yolov3.py\", line 225, in forward\n",
      "    assert np.allclose(\n",
      "AssertionError\n"
     ]
    }
   ],
   "source": [
    "!python train_coco.py \\\n",
    "    --dataset_dir /data/COCO \\\n",
    "    --anno_path /data/COCO/annotations/instances_train2017.json \\\n",
    "    --weights_path weights/darknet53.conv.74 \\\n",
    "    --gpu_id 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: train_custom.py [-h] --dataset_dir DATASET_DIR\n",
      "                       [--weights_path WEIGHTS_PATH]\n",
      "                       [--checkpoint_path CHECKPOINT_PATH]\n",
      "                       [--config_path CONFIG_PATH] [--gpu_id GPU_ID]\n",
      "                       [--save_dir SAVE_DIR] [--save_interval SAVE_INTERVAL]\n",
      "train_custom.py: error: unrecognized arguments: --train_list_path /data/custom_detection/train.txt --val_list_path /data/custom_detection/val.txt\n"
     ]
    }
   ],
   "source": [
    "!python train_custom.py \\\n",
    "    --dataset_dir /data/custom_detection \\\n",
    "    --train_list_path /data/custom_detection/train.txt \\\n",
    "    --val_list_path /data/custom_detection/val.txt \\\n",
    "    --weights_path weights/darknet53.conv.74 \\\n",
    "    --gpu_id 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}